# 进程与线程

在学习本节时，请读者思考以下问题：

1. 为什么要引入进程？
2. 什么是进程？进程由什么组成？
3. 进程是如何解决问题的？

## 进程的概念和特征

### 进程的概念

在多道程序环境下，允许多个程序并发执行，此时它们将失去封闭性，并具有间断性及不可再现性的特征。为此引入了进程（Process）的概念，以便更好地描述和控制程序的并发执行，实现操作系统的并发性和共享性（最基本的两个特性）。

为了使参与并发执行的程序（含数据）能独立地运行，必须为之配置一个专门的数据结构，称为进程控制块（Process Control Block，PCB）。系统利用 PCB 来描述进程的基本情况和运行态，进而控制和管理进程。相应地，由程序段、相关数据段和 PCB 三部分构成了进程映像（进程实体）。所谓创建进程，实质上是创建进程映像中的 PCB；而撤销进程，实质上是撤销进程的 PCB。值得注意的是，进程映像是静态的，进程则是动态的。

注意：PCB 是进程存在的唯一标志！

从不同的角度，进程可以有不同的定义，比较典型的定义有：

1. 进程是程序的一次执行过程。
2. 进程是一个程序及其数据在处理机上顺序执行时所发生的的活动。
3. 进程是具有独立功能的程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。

引入进程实体的概念后，我们可把传统操作系统中的进程定义为：“进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。”

读者要准确理解上面所说的系统资源。这里的系统资源是指处理机、存储器和其他设备服务于某个进程的 “时间”，例如把处理机资源理解为处理机的时间片才是准确的。因为进程是这些资源分配和调度的独立单位，即 “时间片” 分配的独立单位，这就决定了进程一定是一个动态的、过程性的概念。

### 进程的特征

进程是由多程序的并发执行而引出的，它和程序是两个截然不同的概念。进程的基本特征是对比单个程序的顺序执行提出的，也是对进程管理提出的基本要求。

1. 动态性。进程是程序的一次执行，它有着创建、活动、暂停、终止等过程，具有一定的生命周期，是动态地产生、变化和消亡的。动态性是进程最基本的特征。
2. 并发性。指多个进程实体同时存在于内存中，能在一段时间内同时运行。并发性是进程的重要特征，同时也是操作系统的重要特征。引入进程的目的就是为了使程序能与其他进程的程序并发执行，以提高资源利用率。
3. 独立性。指进程实体是一个能独立运行、独立获得资源和独立接受调度的基本单位。凡未建立 PCB 的程序，都不能作为一个独立的单位参与运行。
4. 异步性。由于进程的相互制约，使得进程具有执行的间断性，即进程按各自独立的、不可预知的速度向前推进。异步性会导致执行结果的不可再现性，为此在操作系统中必须配置相应的进程同步机制。
5. 结构性。每个进程都配置一个 PCB 对其进行描述。从结构上看，进程实体是由程序段、数据段和进程控制端三部分组成的。

通常不会直接考查进程有什么特性，所以读者对上面的五个特性不求记忆，只求理解。

## 进程的状态与转换

进程在其生命周期内，由于系统中各进程之间的相互制约关系及系统的运行环境的变化，使得进程的状态也在不断地发生变化（一个进程会尽力若干不同状态）。通常进程有以下五种状态，前三种是进程的基本状态。

1. 运行态。进程正在处理机上运行。在单处理机环境下，每个时刻最多只有一个进程处于运行态。
2. 就绪态。进程已处于准备运行的状态，即进程获得了除处理机外的一切所需资源，一旦得到处理机即可运行。
3. 阻塞态，又称等待态。进程正在等待某一事件而暂停运行，如等待某资源为可用（不包括处理机）或等待输入/输出完成。即使处理机空闲，该进程也不能运行。
4. 创建态。进程正在被创建，尚未转到就绪态态。创建进程通常需要多个步骤：首先申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息；然后由系统为该进程分配运行时所必需的资源；最后把该进程转入就绪态。
5. 结束态。进程正从系统中消失，可能是进程正常结束或其他原因中断退出运行。进程需要结束运行时，系统首先必须置该进程为结束态，然后再进一步处理资源释放和回收等工作。

注意区别就绪态和等待态：就绪态是指进程仅缺少处理机，只要获得处理机资源就立即执行；而等待态是指进程需要其他资源（除了处理机）或等待某一事件。之所以把处理机和其他资源划分开，是因为在分时系统的时间片轮转机制中，每个进程分到的时间片是若干毫秒。也就是说，进程得到的处理机的时间很短且非常频繁，进程在运行过程中实际上是频繁地转换到就绪态的；而其他资源（如外设）的使用和分配或某一事件的发生（如 I/O 操作的完成）对应的时间相对来说很长，进程转换到等待态的次数也相对较少。这样来看，就绪态和等待态是进程生命周期中两个完全不同的状态，显然需要加以区分。

下图说明了 5 种进程状态的转换，而三种基本状态之间的转换如下：

images（王道 图 2.1 5种进程状态的转换）

- 就绪态 -> 运行态：处理就绪态的进程被调度后，获得处理机资源（分派处理机时间片），于是进程由就绪态转换为运行态。
- 运行态 -> 就绪态：处于运行态的进程在时间片用完后，不得不让出处理机，从而进程由运行态转换为就绪态。此外，在可剥夺的操作系统中，当有更高优先级的进程就绪时，调度程序将正执行的进程转换为就绪态，让更高优先级的进程执行。
- 运行态 -> 阻塞态：进程请求某一资源（如外设）的使用和分配或等待某一事件的发生（如 I/O 操作的完成）时，它就从运行态转换为阻塞态。进程以系统调用的形式请求操作系统提供服务，这是一种特殊的、由运行用户态程序调用操作系统内核过程的形式。
- 阻塞态 -> 就绪态：进程等待的事件到来时，如 I/O 操作结束或中断结束时，中断处理程序必须把相应进程的状态由阻塞态转换为就绪态。

需要注意的是，一个进程从运行态变成阻塞态是主动的行为，而从阻塞态变成就绪态是被动的行为，需要其他相关进程的协助。

## 进程控制

进程控制的主要功能是对系统中的所有进程实施有效的管理，它具有创建新进程、撤销已有进程、实现进程状态转换等功能。在操作系统中，一般把进程控制用的程序段称为原语，原语的特点是执行期间不允许中断，它是一个不可分割的基本单位。

### 进程的创建

允许一个进程创建另一个进程。此时创建者称为父进程，被创建的进程称为子进程。子进程可以继承父进程所拥有的资源。当子进程被撤销时，应将其从父进程那里获得的资源归还给父进程。此外，在撤销父进程时，必须同时撤销其所有的子进程。

在操作系统中，终端用户登录系统、作业调度、系统提供服务、用户程序的应用请求等都会引起进程的创建。操作系统创建一个新进程的过程如下（创建原语）：

1. 新进程分配一个唯一的进程标识号，并申请一个空白的 PCB（PCB 是有限的）。若 PCB 申请失败，则创建失败。
2. 为进程分配资源，为新进程的程序和数据及用户栈分配必要的内存空间（在 PCB 中体现）。注意，若资源不足（如内存空间），则并不是创建失败，而是处于 “等待态” 或称 “阻塞态”，等待的是内存这个资源。
3. 初始化 PCB，主要包括初始化标志信息、初始化处理机状态信息和初始化处理机控制信息，以及设置进程的优先级等。
4. 若进程就绪队列能够接纳新进程，则将新进程插入就绪队列，等待被调度运行。

### 进程的终止

引起进程终止的事件主要有：正常结束，表示进程的任务已经完成并准备退出运行。异常结束，表示进程在运行时，发生了某种异常事件，使程序无法继续运行，如存储区越界、保护错、非法指令、特权指令错、I/O 故障等。外界干扰是指进程应外界的请求二终止运行，如操作员或操作系统干预、父进程请求和父进程终止。

操作系统终止进程的过程如下（撤销原语）：

1. 根据被终止进程的标识符，检索 PCB，从中读出该进程的状态。
2. 若被终止进程处于执行状态，立即终止该进程的执行，将处理机资源分配给其他进程。
3. 若该进程还有子进程，则应将其所有子进程终止。
4. 将该进程所拥有的全部资源归还给其父进程，或归还给操作系统。
5. 将该 PCB 从所在队列（链表）中删除。

### 进程的阻塞和唤醒

正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作可做等，由系统自动执行阻塞原语（Block），使自己由运行态变为阻塞态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得 CPU），才可能将其转为阻塞态。阻塞原语的执行过程如下：

1. 找到将要被阻塞进程的标识号对应的 PCB。
2. 若该进程为运行态，则保护其现场，将其状态转为阻塞态，停止运行。
3. 把该 PCB 插入相应事件的等待队列。

当被阻塞进程所期待的事件出现时，如它所启动的 I/O 操作已完成或其所期待的数据已到达，由有关进程（如提供数据的进程）调用唤醒原语（Wakeup），将等待该事件的进程唤醒。唤醒原语的执行过程如下：

1. 在该事件的等待队列中找到相应进程的 PCB。
2. 将其从等待队列中移出，并置其状态为就绪态。
3. 把该 PCB 插入就绪队列，等待调度程序调度。

需要注意的是，Block 原语和 Wakeup 原语是一对作用刚好相反的原语，必须成对使用。Block 原语是由被阻塞进程自我调用实现的，而 Wakeup 原语则是由一个与被唤醒进程合作或被其他相关的进程调用实现的。

### 进程切换

对于通常的进程而言，其创建、撤销及要求由系统设备完成的 I/O 操作，都是利用系统调用而进入内核，再由内核中的相应处理程序予以完成的。进程切换同样是在内核的支持下实现的，因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。

进程切换是指处理机从一个进程的运行转到另一个进程上运行，在这个过程中，进程的运行环境产生了实质性的变化。进程切换的过程如下：

1. 保存处理机上下文，包括程序计数器和其他寄存器。
2. 更新 PCB 信息。
3. 把进程的 PCB 移入相应的队列，如就绪、在某事件阻塞等队列。
4. 选择另一个进程执行，并更新其 PCB。
5. 更新内存管理的数据结构。
6. 恢复处理机上下文。

注意，进程切换与处理机模式切换是不同的，模式切换时，处理机逻辑上可能还在同一进程中运行。若进程因中断或异常进入核心态运行，执行完后又回到用户态刚被中断的程序运行，则操作系统只需恢复进程进入内核时所保存的 CPU 现场，而无须改变当前进程的环境信息。但若要切换进程，当前运行进程改变了，则当前进程的环境信息也需要改变。

注意：“调度” 和 “切换” 的区别，调度是指决定资源分配给哪个进程的行为，是一中决策行为；切换是指实际分配的行为，是执行行为，一般来说，先有资源的调度，然后才有进程的切换。

## 进程的组织

进程是一个独立的运行单位，也是操作系统进行资源分配和调度的基本单位。它一般由以下三部分组成。

### 进程控制块

进程创建时，操作系统新键一个 PCB 结构，该结构之后常驻内存，任意时刻都可以存取，并在进程结束时删除。PCB 是进程实体的一部分，是进程存在的唯一标志。

创建一个进程时，系统为该进程建立一个 PCB；进程执行时，系统通过其 PCB 了解进程的现行状态信息，以便对其进行控制和管理；进程结束时，系统收回其 PCB，该进程随之消亡。操作系统通过 PCB 表来管理和控制进程。

下表是一个 PCB 的实例。PCB 主要包括进程描述信息、进程控制和管理信息、资源分配清单和处理机相关信息等。各部分的主要说明如下：

|进程描述信息|进程控制和管理信息|资源分配清单|处理机相关信息|
|:---:|:---:|:---:|:---:|
|进程标识符（PID）|进程当前状态|代码段指针|通用寄存器值|
|用户标识符（UID）|进程优先级|数据段指针|地址寄存器值|
||代码运行入口地址|堆栈段地址|控制寄存器值|
||程序的外存地址|文件描述符|标志寄存器值|
||进入内存时间|键盘|状态字|
||处理机占用时间|鼠标||
||信号量使用|||

1. 进程描述信息。进程标识符：标志各个进程，每个进程都有一个唯一的标识号。用户标识符：进程归属的用户，用户标识符主要为共享和保护服务。
2. 进程控制和管理信息。进程当前状态：描述进程的状态信息，作为处理机分配调度的依据。进程优先级：描述进程抢占处理机的优先级，优先级高的进程可优先获得处理机。
3. 资源分配清单，用于说明有关内存地址空间或怩地址空间的状况，所打开文件的列表和所使用的输入/输出设备信息。
4. 处理机相关信息，主要指处理机中各寄存器的值，当进程被切换时，处理机状态信息都必须保存在相应的 PCB 中，以便在该进程重新执行时，能从断点继续执行。

在一个系统中，通常存在着许多进程，有的处于阻塞态，而且阻塞的原因各不相同。为了方便进程的调度和管理，需要将各进程的 PCB 用适当的方法组织起来。目前，常用的组织方式有链接方式和索引方式两种。链接方式将同一状态的 PCB 链接成一个队列，不同状态对应不同的队列，也可把处于阻塞态的进程的 PCB，根据其阻塞原因的不同，排成多个阻塞队列。索引方式将同一状态的进程组织在一个索引表中，索引表的表项指向相应的 PCB，不同状态对应不同的索引表，如就绪索引表和阻塞索引表等。

### 程序段

程序段就是能被进程调度程序调度到 CPU 执行的程序代码段。注意，程序可被多个进程共享，即多个进程可以运行同一个程序。

### 数据段

一个进程的数据段，可以是进程对应的程序加工处理的原始数据，也可以是程序执行时产生的中间或最终结果。

## 进程的通信

进程通信是指进程之间的信息交换。PV 操作是低级通信方式，高级通信方式是指以较高的效率传输大量数据的通信方式。高级通信方法主要有以下三类。

### 共享存储

在通信的进程之间存在一块可直接访问的共享空间，通过对这片共享空间进行写/读操作实现进程之间的信息交换，如下图所示。在对共享空间进行写/读操作时，需要使用同步互斥工具（如 P 操作、V 操作），对共享空间的写/读进行控制。共享存储又分为两种：低级方式的共享是基于数据结构的共享；高级方式的共享则是基于存储区的共享。操作系统只负责为通信进程提供可共享使用的存储空间和同步互斥工具，而数据交换则由用户自己安排读/写指令完成。

images（王道 图 2.2 共享存储）

注意，用户进程空间一般都是独立的，进程运行期间一般不能访问其他进程的空间，要想让两个用户进程共享空间，必须通过特殊的系统调用实现，而进程内的线程是自然共享进程空间的。

简单理解就是，甲和乙中间有一个大布袋，甲和乙交换物品是通过大布袋进行的，甲把物品放在大布袋里，乙拿走。但乙不能直接到甲的手中拿东西，甲也不能直接到乙的手中拿东西。

### 消息传递

在消息传递系统中，进程间的数据交换是以格式化的消息（Message）为单位的。若通信的进程之间不存在可直接访问的共享空间，则必须利用操作系统提供的消息传递方法实现进程通信。进程通过系统提供的发送消息和接收消息两个原语进行数据交换。

images（王道 图 2.3 消息传递）

1. 直接通信方式。发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓冲队列上，接收进程从消息缓冲队列中取得消息，如上图所示。
2. 间接通信方式。发送进程把消息发送到某个中间实体，接收进程从中间实体取得消息。这种中间实体一般称为信箱，这种通信方式又称信箱通信方式。该通信方式广泛应用于计算机网络中，相应的通信系统称为电子邮件系统。

简单理解就是，甲要告诉乙某些事情，就要写信，然后通过邮差送给乙，直接通信就是邮差把信直接送到乙的手上；间接通信就是乙家门口有一个邮箱，邮差把信放到邮箱里。

### 管道通信

管道通信是消息传递的一种特殊方式，见下图。所谓 “管道”，是指用于连接一个读进程和一个写进程以实现它们之间的通信的一个共享文件，又名 pipc 文件。向管道（共享文件）提供输入的发送进程（即写进程），以字符流形式将大量的数据送入（写）管道；而接收管道输出的接收进程（即读进程）则从管道中接收（读）数据。为了协调双方的通信，管道机制必须提供以下三方面的协调能力：互斥、同步和确定对方的存在。

images（王道 图 2.4）

下面以 LInux 中的管道为例进行说明。在 Linux 中，管道是一种使用非常频繁的通信机制。从本质上说，管道也是一种文件，但它又和一般的文件有所不同，管道可以克服使用文件进行通信的两个问题，具体表现如下：

1. 限制管道的大小。实际上，管道是一个固定大小的缓冲区。在 Linux 中，该缓冲区的大小为 4KB，这使得它的大小不像文件那样不加检验地增长。使用单个固定缓冲区也会带来问题，比如在写管道时可能变满，这种情况发生时，随后对管道的 write() 调用将默认地被阻塞，等待某些数据被读取，以便腾出足够的空间供 write() 调用写。
2. 读进程也可能工作得比写进程快。当所有当前进程数据已被读取时，管道变空。当这种情况发生时，一个随后的 read() 调用将默认地被阻塞，等待某些数据被写入，这解决了 read() 调用返回文件结束的问题。

注意：从管道读数据是一次性操作，数据一旦被读取，它就从管道中被抛弃，释放空间以便写更多的数据。管道只能采用半双工通信，即某一时刻只能单向传输。要实现父子进程双方互动通信，需要定义两个管道。

管道可以理解为共享存储的优化和发展，因为在共享存储中，若某进程要访问共享存储空间，则必须没有其他进程在该共享存储空间中进行写操作，否则访问行为就会被阻塞。而管道通信中，存储空间进化成了缓冲区，缓冲区只允许一边写入、另一边读出，因此只要缓冲区中有数据，进程就能从缓冲区中读出，而不必担心会因为其他进程在其中进行写操作而遭到阻塞，因为写进程会先把缓冲区写满，然后才让读进程读，当缓冲区中还有数据时，写进程不会往缓冲区写数据。当然，这也决定了管道通信必然是半双工通信。

## 线程概念和多线程模型

### 线程的基本概念

引入进程的目的是为了更好地使多道程序并发执行，提高资源利用率和系统吞吐量，增加并发程度；而引入线程的目的则是为了减小程序在并发执行时所付出的时空开销，提高操作系统的并发性能。

线程最直接的理解就是 “轻量级进程”，它是一个基本的 CPU 执行单元，也是程序执行流的最小单位，由线程 ID、程序计数器、寄存器集合和堆栈醉成。线程进程中的一个实体，是被系统独立调度和分派的基本单位，线程自己不拥有系统资源，只拥有一点儿在运行中必不可少的资源，但它可与同属一个进程的其他线程共享进程所拥有的全部资源，一个线程可以创建和撤销另一个线程，同一进程中的多个线程之间可以并发执行。由于线程之间的相互制约，致使线程在运行中呈现出间断性。线程也有就绪、阻塞和运行三种基本状态。

引入线程后，进程的内涵发生了改变，进程只作为除 CPU 外的系统资源的分配单元，线程则作为处理机的分配单元。由于一个线程内部有多个线程，若线程的切换发生在同一个进程内部，则只需要很少的时空开销。

### 线程与进程的比较

1. 调度。在传统的操作系统中，拥有资源和独立调度的基本单位都是进程。在引入线程的操作系统中，线程是独立调度的基本单位，进程是拥有资源的基本单位。在同一进程中，线程的切换不会引起进程切换。在不同进程中进行线程切换，如从一个进程内的线程切换到另一个进程中的线程时，会引起进程切换。
2. 拥有资源。不论是传统操作系统还是设有线程的操作系统，进程都是拥有资源的基本单位，而线程不拥有系统资源（也有一点儿必不可少的资源），但线程可以访问其隶属进程的系统资源。要知道，若线程也是拥有资源的单位，则切换线程就需要较大的时空开销，线程这个概念的提出就没有意义。
3. 并发性。在引入线程的操作系统中，不仅进程之间可以并发执行，而且多个线程之间也可以并发执行，从而使操作系统具有更好的并发性，提高了系统的吞吐量。
4. 系统开销。由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，因此操作系统所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度到进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器的内容，开销很小。此外，由于同一进程内的多个线程共享进程的地址空间，因此这些线程之间的同步与通信非常容易实现，甚至无需操作系统的干预。
5. 地址空间和其他资源（如打开的文件）。进程的地址空间之间的互相独立，同一进程的各线程间共享进程的资源，某进程内的线程对于其他进程不可见。
6. 通信方面。进程间通信（IPC）需要进程同步和互斥手段的辅助，以保证数据的一致性，而线程间可以直接读/写进程数据段（如全局变量）来进行通信。

### 线程的属性

多线程操作系统把线程作为独立运行（或调度）的基本单位，此时的进程已不再是一个基本的可执行实体，但它仍具有与执行相关的状态。所谓进程处于 “执行” 状态，实际上是指该进程中的某线程正在执行。线程的主要属性如下：

1. 线程是一个轻型实体，它不拥有系统资源，但每个线程都应有一个唯一的标识符和一个线程控制块，线程控制块记录了线程执行的寄存器和栈等现场状态。
2. 不同的线程可以执行相同的程序，即同一个服务程序被不同的用户调用时，操作系统把它们创建成不同的线程。
3. 同一进程中的各个线程共享该进程所拥有的资源。
4. 线程是处理机的独立调度单位，多个线程是可以并发执行的。在单 CPU 的计算机系统中，各线程可交替地占用 CPU；在多 CPU 的计算机系统中，各线程可同时占用不同的 CPU，若各个 CPU 同时为一个进程内的各线程服务，则可以缩短进程的处理时间。
5. 一个线程被创建后，便开始了它的生命周期，直至终止。线程在生命周期内会经历阻塞态、就绪态和运行态等各种状态变化。

为什么线程的提出有利于提高系统并发性？可以这样来理解：由于有了线程，线程切换时，有可能会发生进程切换，也有可能不发生进程切换，平均而言每次切换所需的开销就变小了，因此能够让更多的线程参与并发，而不会影响到响应时间等问题。

### 线程的实现方式

线程的实现可以分为两类：用户级线程（User-Level Thread，ULT）和内核级线程（Kernel-Level Thread，KLT）。内核级线程又称内核支持的线程。

在用户级线程中，有关线程管理的所有工作都由应用程序完成，内核意识不到线程的存在。应用程序可以通过使用线程库设计成多线程程序。通常，应用程序从单线程开始，在该线程中开始运行，在其运行的任何时刻，可以通过调用线程库中的派生例程创建一个在相同进程中运行的新线程。下图说明了用户级线程的实现方式。

images（王道 图 2.5 用户级和内核级线程 (a) 用户级方式）

在内核级线程中，线程管理的所有工作由内核完成，应用程序没有进行线程管理的代码，只有一个到内核级线程的编程接口。内核为进程及其内部的每个线程维护上下文信息，调度也在内核基于线程架构的基础上完成。下图说明了内核级线程的实现方式。

images（王道 图 2.5 用户级和内核级线程 (b) 内核级方式）

有些系统中使用组合方式的多线程实现。线程床架你完全在用户空间中完成，线程的调度和同步也在应用程序中进行。一个应用程序中的多个用户级线程被映射到一些（小于等于用户级线程的数目）内核级线程上。下图说明了用户级与内核级的组合实现方式。

images（王道 图 2.5 用户级和内核级线程 (c) 组合实现）

### 多线程模型

有些系统同时支持用户线程和内核线程，由此产生了不同的多线程模型，即实现用户级线程和内核级线程的连接方式。

1. 多对一模型。将多个用户级线程映射到一个内核级线程，线程管理在用户空间完成。此模式中，用户级线程对操作系统不可见（即透明）。
   优点：线程管理是在用户空间进行的，因而效率比较高。
   缺点：一个线程在使用内核服务时被阻塞，整个进程都会被阻塞；多个线程不能并行地运行在多处理机上。

2. 一对一模型。将每个用户级线程映射到一个内核级线程。
   优点：当一个线程被阻塞后，允许另一个线程继续执行，所以并发能力较强。
   缺点：没创建一个用户级线程都需要创建一个内核级线程与其对应，这样创建线程的开销比较大，会影响到应用程序的性能。

3. 多对多模型。将  n 个用户级线程映射到 m 个内核级线程上，要求 m $ \leq $ n。

特点：在多对一模型和一对一模型中取了个折中，克服了多对一模型的并发度不高的缺点，又克服了一对一模型的一个用户进程占用太多内核级线程，开销太大的缺点。又拥有多对一模型和一对一模型各自的优点，可谓集两者之所长。

# 处理机调度

在学习本节时，请读者思考一下问题：

1. 为什么要进行处理机调度？
2. 调度算法有哪几种？集合第 1 章学习的分时操作系统和实时操作系统，思考哪种调度散发比较合适这两种操作系统。

希望读者能够在学习调度散发前，先自己思考一些调度算法，在学习的过程中注意把自己的想法与这些经典的算法进行对比，并学会计算一些调度算法的周转时间。

## 调度的概念

### 调度的基本概念

在多道程序系统中，进程的数量往往多于处理机的个数，因此进程争用处理机的情况在所难免。处理机调度是对处理机进行分配，即从就绪队列中按照一定的算法（公平、高效）选择一个进程并将处理机分配个它运行，以实现进程并发地执行。

处理机调度是多道程序操作系统的基础，是操作系统设计的核心问题。

### 调度的层次

一个作业从提交开始直到完成，往往要经历以下三级调度，如下图所示。

images（王道 图 2.6 处理机的三级调度）

1. 作业调度。又称高级调度，其主要任务是按一定的原则从外存上处于后备状态的作业中挑选一个（或多个）作业，给它（们）分配内存、输入/输出设备等必要的资源，并建立相应的进程，以使它（们）获得竞争处理机的权利。简言之，作业调度就是内存与辅存之间的调度。对于每个作业只调入一次、调出一次。
   多多批处理系统中大多配有作业调度，而其他系统中通常不需要配置作业调度。作业调度的执行频率较低，通常为几分钟一次。

2. 中级调度。又称内存调度，其作用是提高内存利用率和系统吞吐量。为此，应将那些暂时不能运行的进程调至外存等待，把此时的进程状态称为挂起态。当它们已具备运行条件且内存又稍有空闲时，由中级调度来决定把外存上的那些已具备运行条件的就绪进程，再重新调入内存，并修改其状态为就绪态，挂在就绪队列上等待。
3. 进度调度。又称低级调度，其主要任务是按照某种方法和策略从就绪队列中选取一个进程，将处理机分配个它。进程调度是操作系统中最基本的一种调度，在一般的操作系统中都必须配置进程调度。进程调度的频率很高，一般几十毫秒一次。

### 三级调度的联系

作业调度从外存的后备队列中选择一批作业进入内存，为它们建立进程，这些进程被送入就绪队列，进程调度从就绪队列中选出一个进程，并把其状态改为运行态，把 CPU 分配给它。中级调度是为了提高内存的利用率，系统将那些暂时不能运行的进程挂起来。当内存空间宽松时，通过中级调度选择具备运行条件的进程，将其唤醒。

1. 作业调度为进程活动做准备，进程调度使进程正常活动起来，中级调度将暂时不能运行的进程挂起，中级调度处于作业调度和进程调度之间。
2. 作业调度次数少，中级调度次数略多，进程调度频率最高。
3. 进程调度是最基本的，不可或缺。

## 调度的时机、切换与过程

进程调度和切换程序是操作系统内核程序。请求调度的事件发生后，才可能运行进程调度程序，调度了新的就绪进程后，才会进行进程间的切换。理论上这三件事情应该顺序执行，但在实际设计中，操作系统内核程序运行时，若某时发生了引起进程调度的因素，则不一定能够马上进行调度与切换。

现代操作系统中，不能进行进程的调度与切换的情况有以下几种：

1. 在处理中断的过程中。中断处理过程复杂，在实际上很难做到进程切换，而且中断处理是系统工作的一部分，逻辑上不属于某一进程，不应被剥夺处理机资源。
2. 进程在操纵系统内核程序临界区中。进入临界区后，需要独占式地访问共享数据，理论上必须加锁，以防止其他并行程序进入，在解锁前不应切换到其他进程运行，以加快该共享数据的释放。
3. 其他需要完全屏蔽中断的原子操作过程中。如加锁、解锁、中断现场保护、恢复等原子操作。在原子过程中，连中断都要屏蔽，更不应该进行调度与切换。

若在上述过程中发生了引起调度的条件，则不能马上进行调度和切换，应置系统的请求调度标志，直到上述过程结束后才进行相应的调度与切换。

应该进行进程调度与切换的情况如下：

1. 发生引起调度条件且当前进程无法继续运行下去时，可以马上进行调度与切换。若操作系统只在这种情况下进行进程调度，则是非剥夺调度。
2. 中断处理结束或自陷处理结束后，返回被中断进行的用户态程序执行现场前，若置上请求调度标志，即可马上进行进程调度与切换。若操作系统支持这种情况下的运行调度程序，则实现了剥夺方式的调度。

进程切换往往在调度完成后立刻发生，它要求保存原进程当前切换点的现场信息，恢复被调度进程的现场信息。现场切换时，操作系统内核将原进程的现场信息推入当前进程的内核堆栈来保存它们，并更新堆栈指针。内核完成从新进程的内核栈中装入新进程的现场信息，更新当前运行进程空间指针、重设 PC 寄存器等相关工作之后，开始运行新的进程。

## 进程调度方式

所谓进程调度方式，是指当某个进程正在处理机上执行时，若有某个更为重要或紧迫的进程需要处理，即有优先权更高的进程进入就绪队列，此时应如何分配处理机。

通常有以下两种进程调度方式：

1. 非剥夺调度方式，又称非抢占方式。非剥夺调度方式是指当一个进程正在处理机上执行时，即使有某个更为重要或紧迫的进程进入就绪队列，仍然让正在执行的进程继续执行，直到该进程完成或发生某种事件而进入阻塞态时，才把处理机分配给更为重要或紧迫的进程。
   在非剥夺调度方式下，一旦把 CPU 分配给一个进程，该进程就会保持 CPU 直到终止或转换到等待态。这种方式的优点是实现简单、系统开销小，适用于大多数的批处理系统，但它不能用于分时系统和大多数的实时系统。

2. 剥夺调度方式，又称抢占方式。剥夺调度方式是指当一个进程正在处理机上执行时，若有某个更为重要或紧迫的进程需要使用处理机，即立即暂停正在执行的进程，将处理机分配给这个更为重要或紧迫的进程。
   采用剥夺式的调度，对提高系统吞吐率和响应效率都有明显的好处。但 “剥夺” 不是一种任意性行为，必须遵循一定的原则，主要有优先权、咱进城优先和时间片原则等。

## 调度的基本准则

不同的调度算法具有不同的特性，在选择调度算法时，必须考虑算法的特性。为了比较处理机调度算法的性能，人们提出了很多评价准则，下面介绍其中主要的几种：

1. CPU 利用率。CPU 是计算机系统中最重要和昂贵的资源之一，所以应尽可能使 CPU 保持 “忙” 状态，使这一资源利用率最高。
2. 系统吞吐量。表示单位时间内 CPU 完成作业的数量。长作业需要消耗较长的处理机时间，因此会降低系统的吞吐量。而对于短作业，它们所需要消耗的处理机时间较短，因此能提高系统的吞吐量。调度算法和方式的不同，也会对系统的吞吐量产生较大的影响。
3. 周转时间。周转时间是指从作业提交到作业完成所经历的时间，是作业等待、在就绪队列中排队、在处理机上运行及进行输入/输出操作所花费时间的总和。
   作业的周转时间可用公式表示如下：
   
   $$
	周转时间 = 作业完成时间 - 作业提交时间
   $$
   
   平均周转时间是指多个作业周转时间的平均值：
   
   $$
	平均周转时间 = (作业 1 的周转时间+···+作业 n 的周转时间)/n
   $$
   
   带权周转时间是指作业周转时间与作业实际运行时间的比值：
   
   $$
	带权周转时间 = \frac{作业周转时间}{作业实际运行时间}
   $$
   
   平均带权周转时间是指多个作业带权周转时间的平均值：
   
   $$
	平均带权周转时间 = (作业 1 的带权周转时间 +···+ 作业 n 的带权周转时间)/n
   $$

4. 等待时间。等待时间是指进程处于等处理机状态的时间之和，等待时间越长，用户满意度越低。处理机调度算法实际上并不影响作业执行或输入/输出操作的时间，只影响作业在就绪队列中等待所花的时间。因此，衡量一个调度算法的优劣，常常只需简单地考察等待时间。
5. 响应时间。响应时间指从用户提交请求到系统首次产生响应所用的时间。在交互时系统中，周转时间不可能是最好的评价准则，一般采用响应时间作为衡量调度算法的重要准则之一。从用户角度来看，调度策略应尽量降低响应时间，使响应时间处在用户能接收的范围之内。

要想得到一个满足所有用户和系统要求的算法几乎是不可能的。设计调度程序，一方面要满足特定系统用户的要求（如某些实时和交互进程的快速响应要求），另一方面要考虑系统整体效率（如减少整个系统的进程平均周转时间），同时还要考虑调度算法的开销。

## 典型的调度算法

操作系统中存在多种调度算法，有的调度算法适用于作业调度，有的调度算法适用于进程调度，有的调度算法两者都适用。下面介绍几种常用的调度算法。

### 先来先服务（FCFS）调度算法

FCFS 调度算法是一种最简单的调度算法，它既可用于作业调度，又可用于进程调度。在作业调度中，算法每次从后备作业队列中选择最先进入该队列的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列。

在进程调度中，FCFS 调度算法每次从就绪队列中选择最先进入该队列的进程，量处理机分配给它，使之投入运行，直到完成或因某种原因而阻塞时才释放处理机。

下面通过一个实例来说明 FCFS 调度算法的性能。假设系统中有 4 个作业，它们的提交时间分别是 8,8.4,8.8,9，运行时间依次是 2,1,0.5,0.2，系统采用 FCFS 调度算法，这组作业的平均等待时间、平均周转时间和平均带权周转时间见下表。

|作业号|提交时间|运行时间|开始时间|等待时间|完成时间|周转时间|带权周转时间|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|1|8|2|8|0|10|2|1|
|2|8.4|1|10|1.6|11|2.6|2.6|
|3|8.8|0.5|11|2.2|11.5|2.7|5.4|
|4|9|0.2|11.5|2.5|11.7|2.7|13.5|

$$
平均等待时间 t = (0+1.6+2.2+2.3)/4=1.575; \\
平均周转时间 T = (2+2.6+2.7+2.7)/4=2.5; \\
平均带权周转时间 W = (1+2.6+5.4+13.5)/4=5.625
$$

FCFS 调度算法属于不可剥夺算法。从表面上看，它对所有作业都是公平的，但若一个长作业先到达系统，就会使后面的许多短作业等待很长时间，因此它不能作为分时系统和实时系统的主要调度策略。但它常被结合在其他调度策略中使用。例如，在使用优先级作为调度策略的系统中，往往对多个具有相同优先级的进程按 FCFS 原则处理。

FCFS 调度算法的特点是算法简单，但效率低；对长作业比较有利，但对短作业不利（相对 SJF 和高响应比），有利于 CPU 繁忙型作业，而不利于 I/O 繁忙型作业。

### 短作业优先（SJF）调度算法

短作业（进程）优先调度算法是指对短作业（进程）优先调度的算法。短作业优先（SJF）调度算法从后备队列中选择一个或若干估计运行时间最短的作业，将它们调入内存运行；段进程优先（SPF）调度算法从就绪队列中选择一个估计运行时间最短的进程，将处理机分配给它，使之立即执行，直到完成或发生某事件而阻塞时，才释放处理机。

例如，考虑上表中给出的一组作业，若系统采用短作业优先调度算法，其平均等待时间、平均周转时间和平均带权周转时间见下表。

|作业号|提交时间|运行时间|开始时间|等待时间|完成时间|周转时间|带权周转时间|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|1|8|2|8|0|10|2|1|
|2|8.4|1|10.7|2.3|11.7|3.3|3.3|
|3|8.8|0.5|10.2|1.4|10.7|1.9|3.8|
|4|9|0.2|10|1|10.2|1.2|6|

$$
平均等待时间 t = (0+2.3+1.4+1)/4=1.175; \\
平均周转时间 T = (2+3.3+1.9+1.2)/4=2.1; \\
平均带权周转时间 W = (1+3.3+3.8+6)/4=3.525。
$$

SJF 调度算法也存在不容忽视的缺点：

1. 该算法对长作业不利，由上面两表可知，SJF 调度算法中长作业的周转时间会增加。更严重的是，若有一长作业进入系统的后备队列，由于调度程序总是优先调度那些（即使是后进来的）短作业，将导致长作业长期不被调度（“饥饿” 现象，注意区分 “死锁”，后者是系统环形等待，前者是调度策略问题）。
2. 该算法完全未考虑作业的紧迫程度，因而不能保证紧迫性作业会被及时处理。
3. 由于作业的长短只是根据用户所提供的的估计执行时间而定的，而用户又可能会有意或无意地缩短其作业的估计运行时间，致使该算法不一定能真正做到短作业优先调度。

注意，SJF 调度算法的平均等待时间、平均周转时间最少。

### 优先级调度算法

优先级调度算法又称优先权调度算法，它既可用于作业调度，又可用于进程调度。该算法中的优先级用于描述作业运行的紧迫程度。

在作业调度中，优先级调度算法每次从后备作业队列中选择优先级最高的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列。在进程调度中，优先级调度算法每次从就绪队列中选择优先级最高的进程，将处理机分配给它，使之投入运行。

根据新的更高优先级进程能否抢占正在执行的进程，可将该调度算法分为如下两种：

1. 非剥夺式优先级调度算法。当一个进程正在处理机上运行时，即使有某个更为重要或紧迫的进程进入就绪队列，仍然让正在运行的进程继续运行，直到由于其自身的原因而主动让出处理机时（任务完成或等待事件），才把处理机分配给更为重要或紧迫的进程。
2. 剥夺式优先级调度算法。当一个进程正在处理机上运行时，若有某个更为重要或紧迫的进程进入就绪队列，则立即暂停正在运行的进程，将处理机分配给更重要或紧迫的进程。

而根据进程创建后其优先级是否可以改变，可以将进程优先级分为以下两种：

1. 静态优先级。优先级是在创建进程时确定的，且在进程的整个运行期间保持不变。确定静态优先级的主要依据有进程类型、进程对资源的要求、用户要求。
2. 动态优先级。在进程运行过程中，根据进程情况的变化动态调整优先级。动态调整优先级的主要依据有进程占有 CPU 时间的长短、就绪进程等待 CPU 时间的长短。

一般来说，进程优先级的设置可以参照以下原则：

1. 系统进程 > 用户进程。系统进程作为系统管理者，理应拥有更高的优先级。
2. 交互型进程 > 非交互型进程（或前台进程 > 后台进程）。大家平时在使用手机时，在前台运行的正在和你交互的进程应该更快速地响应你，因此自然需要被优先处理，即要有更高的优先级。
3. I/O 型进程 > 计算型进程。所谓 I/O 型进程，是指那些会频繁使用 I/O 设备的进程，而计算型进程是那些频繁使用 CPU 的进程（很少使用 I/O 设备）。我们知道，I/O 设备（如打印机）的处理速度要比 CPU 慢得多，因此若将 I/O 型进程的优先级设置得更高，就更有可能让 I/O 设备尽早开始工作，进而提升系统的整体效率。

### 高响应比优先调度算法

高响应比优先调度算法主要用于作业调度，是对 FCFS 调度算法和 SJF 调度算法的一种综合平衡，同时考虑了每个作业的等待时间和估计的运行时间。在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中选出响应比最高的作业投入运行。

响应比的变化规律可描述为

$$
响应比 R_P = \frac{等待时间+要求服务时间}{要求服务时间}
$$

根据公式可知：

1. 作业的等待时间相同时，要求服务时间越短，响应比越高，有利于短作业。
2. 要求服务时间相同时，作业的响应比由其等待时间决定，等待时间越长，其响应比越高，因而它实现的是先来先服务。
3. 对于长作业，作业的响应比可以随等待时间的增加而提高，等待时间足够长时，其响应比便可升到很高，从而也可获得处理机。因此，克服了饥饿状态，兼顾了长作业。

### 时间片轮转调度算法

时间片轮转调度算法主要适用于分时系统，在这种算法中，系统将所有就绪进程按到达时间的先后次序排成一个队列，进程调度程序总是选择就绪队列的第一个进程执行，即先来先服务的原则，但仅能运行一个时间片，如 100ms。在使用完一个时间片后，即使进程并未完成其运行，它也必须释放出（被剥夺）处理机给下一个就绪的进程，而被剥夺的进程返回到就绪队列的末尾重新排队，等待再次运行。

在时间片轮转调度算法中，时间片的大小对系统性能的影响很大。若时间片足够大，以至于所有进程都能在一个时间片内执行完毕，则时间片轮转调度算法就退化为先来先服务调度算法。若时间片很小，则处理机将在进程间过于频繁地切换，使处理机的开销增大，而真正用于运行用户进程的时间将减少。因此，时间片的大小应选择适当。

时间片的长短通常由以下因素确定：系统的响应时间、就绪队列中的进程数目和系统的处理能力。

### 多级反馈队列调度算法（融合了前几种算法的优点）

多级反馈队列调度算法是时间片轮转调度算法和优先级调度算法的综合发展，如下图所示。通过动态调整进程优先级和时间片大小，多级反馈队列调度算法可以兼顾多方面的系统目标。比如，为提高系统吞吐量和缩短平均周转时间而照顾短进程；为获得较好的 I/O 设备利用率和缩短响应时间而照顾 I/O 型进程；同时，也不必事先估计进程的执行时间。

images（王道 图 2.7 多级反馈队列调度算法）

多级反馈队列调度算法的实现思想如下：

1. 设置多个就绪队列，并为各个队列赋予不同的优先级，第 1 级队列的优先级最高，第 2 级队列次之，其余队列的优先级逐次降低。
2. 赋予各个队列中进程执行时间片的大小各不相同。在优先级越高的队列中，每个进程的运行时间片越小。例如，第 2 级队列的时间片要比第 1 级队列的时间片长 1 倍······第 i + 1 级队列的时间片要比第 i 级队列的时间片长 1 倍。
3. 一个新进程进入内存后，首先将它放入第 1 级队列的末尾，按 FCFS 原则排队等待调度。当轮到该进程执行时，如它能在该时间片完成，便可准备撤离系统；若它在一个时间片结束时尚未完成，调度程序便将该进程转入第 2 级队列的末尾，再同样按 FCFS 原则等待调度执行；若它在第 2 级队列中运行一个时间片后仍未完成，再以同样的方法放入第 3 级队列······如此下去，当一个长进程从第 1 级队列依次降到第 n 级队列后，在第 n 级队列中便采用时间片轮转的方式运行。
4. 仅当第 1 级队列为空时，调度程序才调度第 2 级队列中的进程运行；仅当第 1~(i-1) 级队列均为空时，才会调度第 i 级队列中的进程运行。若处理机正在执行第 i 级队列中的某进程，这时又有新进程进入优先级较高的队列 [第 1~(i-1) 中的任何一个队列]，则此时新进程将抢占正在运行进程的处理机，即由调度程序把正在运行的进程放回第 i 级队列的末尾，把处理机分配个新到的更高优先级的进程。

多级反馈队列的优势有以下几点：

1. 终端型作业用户：短作业优先。
2. 短批处理作业用户：周转时间较短。
3. 长批处理作业用户：经过前面几个队列得到部分执行，不会长期得不到处理。

# 进程同步

在学习本节时，请读者思考一下问题：

1. 为什么要引入进程同步的概念？
2. 不同的进程之间会存在什么关系？
3. 当单纯用本节介绍的方法解决这些问题时会遇到什么新的问题吗？

用 PV 操作解决进程之间的同步互斥问题是这一节的重点，考试已经多次考查过这一内容，读者务必多加练习，掌握好求解问题的方法。

## 进程同步的基本概念

在多道程序环境下，进程是并发执行的，不同进程之间存在着不同的相互制约关系。为了协调进程之间的相互制约关系，引入了进程同步的概念。下面举一个简单的例子来帮大家理解这个概念。例如，让系统计算 1+2x3，假设系统产生两个进程：一个是加法进程，一个是乘法进程。要让计算结果是正确的，一定要让加法进程发生在乘法进程之后，但实际上操作系统具有异步性，若不加以制约，加法进程发生在乘法进程之前是绝对有可能的，因此要制定一定的机制去约束加法进程，让它在乘法进程完成之后才发生，而这种机制就是本节要讨论的内容。

### 临界资源

虽然多个进程可以共享系统中的各种资源，但其中许多资源一次只能为一个进程所用，我们将一次仅允许一个进程使用的资源称为临界资源。许多物理设备都属于临界资源，如打印机等。此外，还有许多变量、数据等都可以被若干进程共享，也属于临界资源。

对临界资源的访问，必须互斥地进行，在每个进程中，访问临界资源的那段代码称为临界区。为了保证临界资源的正确使用，可把临界资源的访问过程分成 4 个部分：

1. 进入区。为了进入临界区使用临界资源，在进入区要检查可否进入临界区。若能进入临界区，则应设置正在访问临界区的标志，以阻止其他进程同时进入临界区。
2. 临界区。进程中访问临界资源的那段代码，又称临界段。
3. 退出区。将正在访问临界区的标志清除。
4. 剩余区。代码中的其余部分。

```
do {
    entry section;       // 进入区
    critical section;    // 临界区
    exit section;        // 退出区
    remainder section;   // 剩余区
}
```

### 同步

同步亦称直接制约关系，是指为完成某种任务而建立的两个或多个进程，这些进程因为需要的某些位置上协调它们的工作次序而等待、传递信息所产生的制约关系。进程间的直接制约关系源于它们之间的相互合作。

例如，输入进程 A 通过单缓冲向进程 B 提供数据。当该缓冲区空时，进程 B 不能获得所需数据而阻塞，一旦进程 A 将数据送入缓冲区，进程 B 就被唤醒。反之，当缓冲区满时，进程 A 被阻塞，仅当进程 B 取走缓冲数据时，才唤醒进程 A。

### 互斥

互斥也称间接制约关系。当一个进程进入临界区使用临界资源时，另一个进程必须等待，当占用临界资源的进程退出临界区后，另一进程才允许去访问此临界资源。

例如，在仅有一台打印机的系统中，有两个进程 A 和进程 B，若进程 A 需要打印时，系统已将打印机分配给进程 B，则进程 A 必须阻塞。一旦进程 B 将打印机释放，系统便将进程 A 唤醒，并将其由阻塞态变为就绪态。

为禁止两个进程同时进入临界区，同步机制应遵循以下准则：

1. 空闲让进。临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区。
2. 忙则等待。当已有进程进入临界区时，其他试图进入临界区的进程必须等待。
3. 有限等待。对请求访问的进程，应保证能在有限时间内进入临界区。
4. 让权等待。当进程不能进入临界区时，应立即释放处理器，防止进程忙等待。

## 实现临界区互斥的基本方法

### 软件实现方法

在进入区设置并检查一些标志来标明是否有进程在临界区中，若已有进程在临界区，则在进入区通过循环检查进行等待，进程离开临界区后则在退出区修改标志。

1. 算法一：单标志法。该算法设置一个公用整型边浪 turn，用于指示被允许进入临界区的进程编号，即若 turn=0，则允许 $P_0$ 进程进入临界区。该算法可确保每次只允许一个进程进入临界区。但两个进程必须交替进入临界区，若某个进程不再进入临界区，则另一个进程也将无法进入临界区（违背 “空闲让进”）。这样很容易造成资源利用不充分。
   若 $P_0$ 顺利进入临界区并从临界区离开，则此时临界区是空闲的，但 $P_1$ 并没有进入临界区的打算，turn=1 一直成立，$P_0$ 就无法再次进入临界区（一直被 while 死循环困住）。

$$
\begin{array}{ll}
P_0进程：     \qquad \qquad \qquad \qquad \quad          P_1进程： \\
while(turn!=0);     \qquad \qquad   while(turn!=1);    \qquad \qquad \qquad  // 进入区  \\
cirtical \quad section;     \qquad \qquad    cirtical \quad section;     \qquad \qquad \qquad    //临界区  \\
turn=1;     \qquad \qquad \qquad \qquad     turn=0;     \qquad \qquad \qquad \qquad \quad    //退出区  \\
remainder \quad section;     \qquad \quad    remainder \quad section;     \qquad \qquad  // 剩余区 \\
\end{array}
$$

2. 算法二：双标志法先检查。该算法的基本思想是在每个进程访问临界区资源之前，先查看临界资源是否正被访问，若正被访问，该进程需等待；否则，进程才进入自己的临界区。为此，设置一个数据 flag[i]，如第 i 个元素值为 FALSE，表示 $P_i$ 进程未进入临界区，值为 TRUE，表示 $P_i$ 进程进入临界区。

$$
\begin{array}{ll}
P_i进程：     \qquad \qquad \qquad \qquad \quad          P_j进程： \\
while(flag[j]); ①    \qquad \qquad   while(flag[i]); ②   \qquad \qquad \qquad  // 进入区  \\
flag[i]=TRUE; ③    \qquad \qquad   flag[j]=TRUE; ④   \qquad \qquad  // 进入区  \\
cirtical \quad section;     \qquad \qquad    cirtical \quad section;     \qquad \qquad \qquad    //临界区  \\
flag[i]=FALSE;     \qquad \qquad     flag[j]=FALSE;     \qquad \qquad \quad    //退出区  \\
remainder \quad section;     \qquad \quad    remainder \quad section;     \qquad \qquad  // 剩余区 \\
\end{array}
$$

   优点：不用交替进入，可联系使用；缺点：$P_i$ 和 $P_j$ 可能同时进入临界区。按序列①②③④执行时，会同时进入临界区（违背 “忙则等待”）。即在检查对方的 flag 后和切换自己的 flag 前有一段时间，结果都检查通过。这里的问题出在检查和修改操作不能一次进行。

3. 算法三：双标志法后检查。算法二先检测对方的进程状态标志，再置自己的标志，由于在检测和放置中可插入另一个进程到达时的检测操作，会造成两个进程在分别检测后同时进入临界区。为此，算法三先将自己的标志设置为 TRUE，在检测对方的状态标志，若对方标志为 TURE，则进入等待；否则进入临界区。

$$
\begin{array}{ll}
P_i进程：     \qquad \qquad \qquad \qquad \quad          P_j进程： \\
flag[i]=TRUE;     \qquad \qquad   flag[j]=TRUE;    \qquad \qquad  // 进入区  \\
while(flag[j]);     \qquad \qquad   while(flag[i]);    \qquad \qquad \qquad  // 进入区  \\
cirtical \quad section;     \qquad \qquad    cirtical \quad section;     \qquad \qquad \qquad    //临界区  \\
flag[i]=FALSE;     \qquad \qquad     flag[j]=FALSE;     \qquad \qquad \quad    //退出区  \\
remainder \quad section;     \qquad \quad    remainder \quad section;     \qquad \qquad  // 剩余区 \\
\end{array}
$$

   两个进程几乎同时都想进入临界区时，它们分别将自己的标志值 flag 设置为 TRUE，并且同时检测对方的状态（执行 while 语句），发现对方也要进入临界区时，双方互相谦让，结果谁也进入不了临界区，从而导致 “饥饿” 现象。

4. 算法四：Peterson‘s Algorithm。为了防止两个进程为进入临界区而无期限等待，又设置了变量 turn，每个进程在先设置自己的标志后再设置 turn 标志。这时，再同时检测另一个进程状态标志和不允许进入标志，以便保证两个进程同时要求进入临界区时，只允许一个进程进入临界区。

$$
\begin{array}{ll}
P_i进程：     \qquad \qquad \qquad \qquad \quad          P_j进程： \\
flag[i]=TRUE;turn=j     \qquad \qquad   flag[j]=TRUE;turn=i    \qquad \qquad  // 进入区  \\
while(flag[j] && turn==j);     \qquad \qquad   while(flag[i] && turn==i);    \qquad \qquad \qquad  // 进入区  \\
cirtical \quad section;     \qquad \qquad    cirtical \quad section;     \qquad \qquad \qquad    //临界区  \\
flag[i]=FALSE;     \qquad \qquad     flag[j]=FALSE;     \qquad \qquad \quad    //退出区  \\
remainder \quad section;     \qquad \quad    remainder \quad section;     \qquad \qquad  // 剩余区 \\
\end{array}
$$

   具体如下，考虑进程 $P_i$，一旦设置 flag[i] = true，就表示它想要进入临界区，同时 turn=j，此时若进程 $P_j$ 已在临界区中，符合进程 $P_i$ 中的 while 循环条件，则 $P_i$ 可以顺利进入，反之亦然。本算法的基本思想是算法一和算法三的结合。利用 flag 解决临界资源的互斥访问，而利用 turn 解决 “饥饿” 现象。
   理解 Peterson's Algorithm 的最好方法就是手动模拟。

### 硬件实现方法

理解本节介绍的硬件实现，对学习后面的信号量很有帮助。计算机提供了特殊的硬件指令，允许对一个字中的内容进行检测和修正，或对两个字的内容进行交换等。通过硬件支持实现临界段问题的方法称为低级方法，或称元方法。

#### （1）中断屏蔽方法

当一个进程正在使用处理机执行它的临界区代码时，防止其他进程进入其临界区进行访问的最简单方法是，禁止一切中断发生，或称之为屏蔽中断、关中断。因为 CPU 只在发生中断时引起进程切换，因此屏蔽中断能够保证当前运行的进程让临界区代码顺利地执行完，进而保证互斥的正确实现，然后执行开中断。其典型模式为

```
···
关中断;
临界区;
开中断;
···
```

这种方法限制了处理机交替执行程序的能力，因此执行的效率会明显降低。对内核来说，在它执行更新变量或列表的几条指令期间，关中断是很方便的，但将关中断的权利交给用户则很不明智，若一个进程关中断后不再开中断，则系统可能会因此终止。

#### （2）硬件指令方法

TestAndSet 指令：这条指令是原子操作，即执行该代码时不允许被中断。其功能是读出指定标志后把该标志设置为真。指令的功能描述如下：

```
boolean TestAndSet(boolean *lock) {
    boolean old;
    old=*lock;
    *lock=true;
    return old;
}
```

可以为每个临界资源设置一个共享布尔变量 lock，表示资源的两种状态：true 表示正被占用，初值为 false。在进程访问临界资源之前，利用 TestAndSet 检查和修改标志 lock；若有进程在临界区，则重复检查，直到进程退出。利用该指令实现进程互斥的算法描述如下：

```
while TestAndSet(&lock);
进程的临界区代码段;
lock=false;
进程的其他代码;
```

Swap指令：该指令的功能是交换两个字（字节）的内容。其功能描述如下：

```
Swap(boolean *a, boolean *b) {
    boolean temp;
    temp=*a;
    *a=*b;
    *b=temp;
}
```

注意：以上对 TestAndSet 和 Swap 指令的描述仅是功能实现，而并非软件实现的定义，事实上，它们是由硬件逻辑直接实现的，不会被中断。

应为每个临界资源设置一个共享变量 lock，初值为 false；在每个进程中再设置一个局部布尔变量 key，用于与 lock 交换信息。在进入临界区前，先利用 Swap 指令交换 lock 与 key 的内容，然后检查 key 的状态；有进程在临界区时，重复交换和检查过程，直到进程退出。利用 Swap 指令实现进程互斥的算法描述如下：

```
key=true;
while(key!=false)
    Swap(&lock, &key);
进程的临界区代码段;
lock=false;
进程的其他代码;
```

硬件方法的优点：适用于任意数目的进程，而不管是单处理机还是多处理机；简单、容易验证其正确性。可以支持进程内有多个临界区，只需为每个临界区设立一个布尔变量。

硬件方法的缺点：进程等待进入临界区时要耗费处理机时间，不能实现让权等待。从等待进程中随机选择一个进入临界区，有的进程可能一直选不上，从而导致 “饥饿” 现象。

无论是软件实现方法还是硬件实现方法，读者只需理解它的执行过程即可，关键是软件实现方法。实际练习和考试中很少让读者写出某种软件和硬件实现方法，因此读者并不需要默写或记忆。以上的代码实现与我们平时在编译器上写的代码意义不同，以上的代码实现是为了表达进程实现同步和互斥的过程，并不是说计算机内部实现同步互斥的就是这些代码。

## 信号量

信号量机制是一种功能较强的机制，可用来解决互斥与同步问题，它只能被两个标准的原语 wait(S) 和 signal(S) 访问，也可即为 “P 操作” 和 “V 操作”。

原语是指完成某种功能且不被分割、不被中断执行的操作序列，通常可由硬件来实现。例如，前述的 Test-and-Set 和 Swap 指令就是由硬件实现的原子操作。原语功能的不被中断执行特性在单处理机上可由软件通过屏蔽中断方法实现。

原语之所以不能被中断执行，是因为原语对变量的操作过程若被打断，可能会去运行另一个对同一变量的操作过程，从而出现临界段问题。若能够找到一种解决临界段问题的元方法，就可以实现对共享变量操作的原子性。

### 整型信号量

整型信号量被定义为一个用于表示资源数目的整型量 S，wait 和 signal 操作可描述为

```
wait(S) {
    while(S<=0) {
        S=S-1;
    }
}
signal(S) {
    S=S+1;
}
```

wait 操作中，只要信号量 $S \leq 0$，就会不断地测试。因此，该机制并未遵循 “让权等待” 的准则，而是使进程处于 “忙等” 的状态。

### 记录型信号量

记录型信号量是不存在 “忙等” 现象的进程同步机制。除需要一个用于代表资源数目的整型变量 value 外，在增加一个进程链表 L，用于链表所有等待该资源的进程。记录型信号量得名于采用了记录型的数据结构。记录型信号量可描述为

```
typedef struct {
    int value;
    struct process *L;
} semaphore;
```

相应的 wait(S) 和 signal(S) 的操作如下：

```
void wait(semaphore S) {    // 相当于申请资源
    S.value--;
    if (S.value<0) {
        add this process to S.L;
        block(S.L);
    }
}
```

wait 操作，S.value-- 表示进程请求一个该类资源，当 S.value < 0 时，表示该类资源已分配完毕，因此进程应调用 block 原语，进行自我阻塞，放弃处理机，并插入该类资源的等待队列 S.L，可见该机制遵循了 "让权等待" 的准则。

```
void signal(semaphore S) {    // 相当于释放资源
    S.value++;
    if (S.value<=0) {
        remove a process P from S.L;
        wakeup(P);
    }
}
```

signal 操作，表示进程释放一个资源，使系统中可供分配的该类资源数增 1，故有 S.value++。若加 1 后仍是 S.value $\leq$ 0，则表示在 S.L 中仍有等待该资源的进程被阻塞，故还应调用 wakeup 原语，将 S.L 中的第一个等待进程唤醒。

### 利用信号量实现同步

信号量机制能用于解决进程间的各种同步问题。设 S 为实现进程 $P_1$、$P_2$ 同步的公共信号量，初值为 0。进程 $P_2$ 中的语句 y 要使用进程 $P_1$ 中语句 x 的运行结果，所以只有当语句 x 执行完成之后语句 y 才可以执行。其实现进程同步的算法如下：

$$
\begin{array}{ll}
semaphore \quad S=0;  \qquad \qquad \qquad // 初始化信号量  \\
P1() \{  \\
\qquad    \sqrt{10000}  \\
\qquad    x;  \qquad \qquad \qquad // 语句x  \\
\qquad    V(S); \qquad \qquad \qquad //告诉进程 P2，语句 x 已经完成 \\
\qquad    ···  \\
\}  \\
P2() \{  \\
\qquad    ··· \\
\qquad    P(S); \qquad \qquad \qquad // 检查语句 x 是否运行完成 \\
\qquad    y; \qquad \qquad \qquad // 检查无误，运行 y 语句  \\
\qquad    ···  \\
\}
\end{array}
$$


若 $P_2$ 先执行到 P(S) 时，S 为 0，执行 P 操作会把进程 $P_2$ 阻塞，并放入阻塞队列；当进程 $P_1$ 中的 x 执行完后，执行 V 操作，把 $P_2$ 从阻塞队列中放回就绪队列，当 $P_2$ 得到处理机时，就得以继续执行。

### 利用信号量实现进程互斥

信号量机制也能很方便地解决进程互斥问题。设 S 为实现进程 $P_1$、$P_2$ 互斥的信号量，由于每次只允许一个进程进入临界区，所以 S 的初值应为 1（即可用资源数为 1）。只需把临界区置于 P(S) 和 V(S) 之间，即可实现两个进程对临界资源的互斥访问。其算法如下：

$$
\begin{array}{ll}
semaphore \quad S=1;  \qquad \qquad \qquad // 初始化信号量  \\
P1() \{  \\
\qquad    ···  \\
\qquad    P(S);  \qquad \qquad \qquad // 准备开始访问临界资源，加锁  \\
\qquad    进程P1的临界区; \\
\qquad    V(S); \qquad \qquad \qquad //访问结束，解锁 \\
\qquad    ···  \\
\}  \\
P2() \{  \\
\qquad    ··· \\
\qquad    P(S); \qquad \qquad \qquad // 准备开始访问临界资源，加锁 \\
\qquad    进程 P2 的临界区; \\
\qquad    V(S); \qquad \qquad \qquad // 访问结束，解锁  \\
\qquad    ···  \\
\}
\end{array}
$$

当没有进程在临界区时，任意一个进程要进入临界区，就要执行 P 操作，把 S 的值减为 0，然后进入临界区；当有进程存在于临界区时，S 的值为 0，再有进程要进入临界区，执行 P 操作时将会被阻塞，直至在临界区中的进程退出，这样便实现了临界区的互斥。

互斥是不同进程对同一信号量进行 P、V 操作实现的，一个进程成功对信号量执行了 P 操作后进入临界区，并在退出临界区后，由该进程本身对该信号量执行 V 操作，表示当前没有进程进入临界区，可以让其他进程进入。

下面简单总结一下 PV 操作在同步互斥中的应用：在同步问题中，若某个行为要用到某种资源，则在这个行为前面 P 这种资源一下；若某个行为会提供某种资源，则在这个行为后面 V 这种资源一下。在互斥问题中，P、V 操作要紧夹使用互斥资源的那个行为，中间不能有其他冗余代码。

### 利用信号量实现前驱关系

信号量也可用来描述程序之间或语句之间的前驱关系。下面给出了一个前驱图，其中 $S_1,S_2,S_3,···,S_6$ 是最简单的程序段（只有一条语句）。为使各程序段能正确执行，应设置若干初始值为 “0” 的信号量。例如，为保证 $S_1 \to S_2$、$S_1 \to S_3$ 的前驱关系，应分别设置信号量 a1、a2。同样，为保证 $S_2 \to S_4$、$S_2 \to S_5$、$S_3 \to S_6$、$S_4 \to S_6$、$S_5 \to S_6$，应设置信号量 b1、b2、c、d、e。

images（王道 图 2.8 前驱图举例）

实现算法如下：

$$
\begin{array}{ll}
semaphore \quad a1=a2=b1=b2=c=d=e=0;  \qquad \qquad \qquad // 初始化信号量  \\
S1() \{  \\
\qquad    ···  \\
\qquad    V(a1); \quad V(a2);  \qquad \qquad \qquad // S1已经运行完成  \\
\}  \\
S2() \{  \\
\qquad    P(a1); \qquad \qquad \qquad // 检查 S1 是否运行完成 \\
\qquad    ···  \\
\qquad    V(b1); \quad V(b2);  \qquad \qquad \qquad // S2已经运行完成  \\
\}
S3() \{  \\
\qquad    P(a2); \qquad \qquad \qquad // 检查 S1 是否运行完成 \\
\qquad    ···  \\
\qquad    V(c);  \qquad \qquad \qquad // S3已经运行完成  \\
\}
S4() \{  \\
\qquad    P(b1); \qquad \qquad \qquad // 检查 S2 是否运行完成 \\
\qquad    ···  \\
\qquad    V(d);  \qquad \qquad \qquad // S4已经运行完成  \\
\}
S5() \{  \\
\qquad    P(b2); \qquad \qquad \qquad // 检查 S2 是否运行完成 \\
\qquad    ···  \\
\qquad    V(e);;  \qquad \qquad \qquad // S5已经运行完成  \\
\}
S6() \{  \\
\qquad    P(c); \qquad \qquad \qquad // 检查 S3 是否运行完成 \\
\qquad    P(d); \qquad \qquad \qquad // 检查 S4 是否运行完成 \\
\qquad    P(e); \qquad \qquad \qquad // 检查 S5 是否运行完成 \\
\qquad    ···  \\
\}
\end{array}
$$

### 分析进程同步和互斥问题的方法步骤

1. 关系分析。找出问题中的进程数，并分歧它们之间的同步和护持关系。同步、互斥、前驱关系直接按照上面例子中的经典范式改写。
2. 整理思路。找出解决问题的关键点，并根据做过的题目找出求解的思路。根据进程的操作流程确定 P 操作、V 操作的大致顺序。
3. 设置信号量。根据上面的两步，设置需要的信号量，确定初值，完善整理。

这是一个比较直观的同步问题，以 $S_2$ 为例，它是 $S_1$ 的后继，所以要用到 $S_1$ 的资源，在前面的简单总结中我们说过，在同步问题中，要用到某种资源，就要在行为（题中统一抽象成L）前面 P 这种资源一下。$S_2$ 是 $S_4$、$S_5$ 的前驱，给 $S_4$、$S_5$ 提供资源，所以要在 L 行为后面 V 由 $S_4$ 和 $S_5$ 代表的资源一下。

## 管程

### 管程的定义

系统中的各种硬件资源和软件资源，均可用数据结构抽象地描述其资源特性，即用少量信息和对资源所执行的操作来表征该资源，而忽略它们的内部结构和实现细节。管程是由一组数据及定义在这组数据之上的对这组数据的操作组成的软件模块，这组操作能初始化并改变管程中的数据和同步进程。

### 管程的组成

1. 局部于管程的共享结构数据说明。
2. 对该数据结构进行操作的一组过程。
3. 对局部于管程的共享数据设置初始值的语句。

相信熟悉面向对象程序设计的读者看到管程的组成后，会立即联想到管程很像一个抽象类。

### 管程的基本特性

1. 局部于管道的数据只能被局部于管程内的过程所访问。
2. 一个进程只有通过调用管程内的过程才能进入管程访问共享数据。
3. 每次仅允许一个进程在管程内执行某个内部过程。

由于管程是一个语言成分，因此管程的互斥访问完全由编译程序在编译时自动添加，无须程序员关注，而且保证正确。

在看完上面对管程的正规化、学术化介绍后，相信不少读者仍然对管程没有清晰的认识，下面我们再用生活化的语言介绍什么是管程。

管程实质上是一个抽象类，这个抽象类有好几个成员变量，系统中任何设备都可通过这几个成员变量进行区分和描述；管程中还有对这些成员变量进行操作的一组成员函数，例如，在对外设的操作中会有 read、write 这类函数。假如进程 $P_0$ 要使用一台打印机，于是管程这个抽象类就会利用初始值语句对自身的几个成员变量赋初值（这个行为不需要程序员关注），特定的几个初始值可以让管程表示成一台打印机，进程 $P_0$ 进入管程后，通过调用管程中的成员函数（即上面所说的过程）对这台打印机进行操作。每次进入这个管程的，只能是一个进程。

上面对管程的描述并不是非常严谨，一些对操作系统认识较为深入的读者可能发现仍然有需要补充的地方，但管程并不是十分重要的考点，上面的内容是为了让读者对管程有一个感性的认识，这个感性的认识可以应付大部分关于冠层的选择题和简单题。

## 经典同步问题

### 生产者-消费者问题

### 读者-写者问题

### 哲学家进餐问题

### 吸烟者问题

# 死锁

在学习本节时，请读者思考以下问题：

1. 为什么会产生死锁？产生死锁有什么条件？
2. 有什么办法可以解决死锁问题？

学完本节，读者应了解死锁的由来、产生条件及基本解决方法，区分死锁的避免和死锁的预防。

## 死锁的概念

### 死锁的定义

在多道程序系统中，由于多个进程的并发执行，改善了系统资源的利用率并提高了系统的处理能力。然而，多个进程的并发执行也带来了新的问题——死锁。所谓死锁，是指多个进程因竞争资源二造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前推进。

下面通过一些实例来说明死锁现象。

先看生活中的一个实例。在一条河上有一座桥，桥面很窄，只能容纳一辆汽车通行，若有两辆汽车分别从桥的左右两端驶上该桥，则会出现下述冲突现象：此时，左边的汽车占有前面左边的一段，要想过桥还需等待右边的汽车让出桥面右边的一段；右边的汽车占有桥面右边的一段，要想过桥还需等待左边的汽车让出桥面左边的一段。此时，若左右两边的汽车都只能向前行驶，则两辆汽车都无法过桥。

在计算机系统中也存在类似的情况。例如，某计算机系统中只有一台打印机和一台输入设备，进程 $P_1$ 正占用输入设备，同时又提出使用打印机的请求，但此时打印机正被进程 $P_2$ 所占用，而 $P_2$ 在未释放打印机之前，又提出请求使用正被 $P_1$ 占用的输入设备。这样，两个进程相互无休止地等待下去，均无法继续执行，此时两个进程陷入死锁状态。

### 死锁产生的原因

#### （1）死锁资源的竞争

通常系统中拥有的不可剥夺资源，其数量不足以满足多个进程运行的需要，使得进程在运行过程中，会因争夺资源而陷入僵局，如磁带机、打印机等。只有对不可剥夺资源的竞争 才可能产生死锁，对可剥夺资源的竞争是不会引起死锁的。

#### （2）进程推进顺序非法

进程在运行过程中，请求和释放资源的顺序不当，也同样会导致死锁。例如，并发进程 $P_1$、$P_2$ 分别保持了资源 $R_1$、$R_2$，而进程 $P_1$ 申请资源 $R_2$、进程 $P_2$ 申请资源 $R_1$ 时，两者都会因为所需资源被占用而阻塞。

信号量使用不当也会造成死锁。进程间彼此想回等待对方发来的消息，也会使得这些进程间无法继续向前推进。例如，进程 A 等待进程 B 发的消息，进程 B 又等待进程 A 发的消息，可以看出进程 A 和 B 不是因为竞争同一资源，而是在等待对方的资源导致死锁。

#### （3）死锁产生的必要条件

产生死锁必须同时满足以下 4 个条件，只要其中任意一个条件不成立，死锁就不会发生。

1. 互斥条件：进程要求对所分配的资源（如打印机）进行排他性控制，即在一段时间内某资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。
2. 不剥夺条件：进程所获得的资源在未使用完之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放（只能是主动释放）。
3. 请求并保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己获得的资源保持不放。
4. 循环等待条件：存在一种进程资源的循环等待链，链中每个进程已获得的资源同时被链中下一个进程所请求。即存在一个处于等待态的进程集合 $\{P_1,P_2,···,P_n\}$，其中 $P_1$ 等待的资源被 $P_{i+1}（i=0,1,···,n-1）$ 占有，$P_n$ 等待的资源被 $P_0$ 占有，如下图所示。

images（王道 图 2.11 循环等待）

直观上看，循环等待条件似乎和死锁的定义一样，其实不然。按死锁定义构成等待环所要求的的条件更严，它要求 $P_i$ 等待的资源必须由 $P_{i+1}$ 来满足，而循环等待条件则无此限制。例如，系统中有两台输出设备，$P_0$ 占有一台，$P_k$ 占有另一台，且 K 不属于集合 {0,1,···,n}。$P_n$ 等待一台输出设备，它可从 $P_0$ 获得，也可能从 $P_k$ 获得。因此，虽然 $P_n$、$P-0$ 和其他一些进程形成了循环等待圈，但 $P_K$ 不在圈内，若 $P_K$ 释放了输出设备，则可打破循环等待，如下图所示。因此循环等待只是死锁的必要条件。

images（王道 图 2.12 满足条件但无死锁）

资源分配图含圈而系统又不一定有死锁的原因是，同类资源数大于 1。但若系统中没类资源都只有一个资源，则资源分配图含圈就变成了系统出现死锁的充分必要条件。

要注意区分不剥夺条件与请求并保持条件。下面用一个简单的例子进行说明：若你手上拿着一个苹果（即使你不打算吃），别人不能把你手上的苹果拿走，则这就是不剥夺条件；若你左手拿着一个苹果，允许你右手再去拿一个苹果，则这就是请求并保持条件。

## 死锁的处理策略

为使系统不发生死锁，必须设法破坏产生死锁的 4 个必要条件之一，或允许死锁产生，但当死锁发生时能检测出死锁，并有能力实现恢复。

### 死锁预防

设置某些限制条件，破坏产生死锁的 4 个必要条件中的一个或几个，以防止发生死锁。

### 避免死锁

在资源的动态分配过程中，用某种方法防止系统进入不安全状态，从而避免死锁。

### 死锁的检测及解除

无须采取任何限制性措施，允许进程在运行过程中发生死锁。通过系统的检测机构及时地检测出死锁的发生，然后采取某种措施解除死锁。

预防死锁和避免死锁都属于事先预防策略，预防死锁的限制条件比较严格，实现起来较为简单，但往往导致系统的效率低，资源利用率低；避免死锁的限制条件相对宽松，资源分配后需要通过算法来判断是否进入不安全状态，实现起来较为复杂。

死锁的几种处理策略的比较见下表。

||资源分配策略|各种可能模式|主要优点|主要缺点|
|:---:|:---:|:---:|:---:|:---:|
|死锁预防|保守，宁可资源闲置|一次请求所有资源，资源剥夺，资源按序分配|适用于突发式处理的进程，不必进行剥夺|效率低，进程初始化时间延长，剥夺次数过多，不便灵活申请新资源|
|死锁避免|是“预防”和“检测”的折中（在运行时判断是否可能死锁）|寻找可能的安全允许顺序|不必进行剥夺|必须知道将来的资源需求：进程不能被长时间阻塞|
|死锁检测|宽松，只要允许就被分配资源|定期检查死锁是否已经发生|不延长进程初始化时间，允许对死锁进行现场处理|通过剥夺解除死锁，造成损失|

## 死锁预防

防止死锁的发生只需破坏死锁产生的 4 个必要条件之一即可。

### 破坏互斥条件

若允许系统资源都能共享使用，则系统不会进入死锁状态。但有些资源根本不能同时访问，如打印机等临界资源只能互斥使用。所以，破坏互斥条件而预防死锁的方法不太可行，而且在有的场合应该保护这种互斥性。

### 破坏不剥夺性条件

当一个已保持了某些不可剥夺资源的进程请求新的资源而得不到满足时，它必须释放已经保持的所有资源，待以后需要再重新申请。这意味着，一个进程已占有的资源会被暂时释放，或者说是被剥夺，或从而破坏了不剥夺条件。

该策略实现起来比较复杂，释放已获得的资源可能造成前一阶段工作的失效，反复地申请和释放资源会增加系统开销，降低系统吞吐量。这种方法常用于状态易于保存和恢复的资源，如 CPU 的寄存器及内存资源，一般不能用于打印机之类的资源。

### 破坏请求并保持条件

采用预先静态分配方法，即进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前，不把它投入运行。一旦投入运行，这些资源就一直归它所有，不再提出其他资源请求，这样就可以保证系统不会发生死锁。

这种方法实现简单，但缺点也显而易见，系统资源被严重浪费，其中有些资源可能仅在运行初期或运行快结束时才使用，甚至根本不使用。而且还会导致 “饥饿” 现象，由于个别资源长期被其他进程占用时，将致使等待该资源的进程迟迟不能开始运行。

### 破坏循环等待条件

为了破坏循环等待条件，可采用顺序资源分配法。首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源，同类资源一次申请完。也就说，只要进程提出申请分配资源 $R_i$，则该进程在以后的资源申请中就只能申请编号大于 $R_i$ 的资源。

这种方法存在的问题是，编号必须相对稳定，这就限制了新类型设备的增加；尽管在为资源编号时已考虑到大多数作业实际使用这些资源的顺序，但也经常会发生作业使用资源的顺序与系统规定顺序不同的情况，造成资源的浪费；此外，这种按规定次序申请资源的方法，也必然会给用户的编程带来麻烦。

## 死锁避免

避免死锁同样属于事先预防策略，但并不是事先采取某种限制破坏死锁的必要条件，而是在资源动态分配过程中，防止系统进入不安全状态，以避免发生死锁。这种方法所施加的限制条件较弱，可以获得较好的系统性能。

### 系统安全状态

避免死锁的方法中，允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次资源分配的安全性。若此次分配不会导致系统进入不安全状态，则将资源分配给进程；否则让进程等待。

所谓安全状态，是指系统能按某种进程推进顺序（$P_1,P_2,···,P_n$）为每个进程 $P_i$ 分配其所需的资源，直至满足每个进程对资源的最大需求，使每个进程都可顺序完成。此时被 $P_1,P_2,···,P_n$ 为安全序列。若系统无法找到一个安全序列，则被系统处于不安全状态。

假设系统中有三个进程 $P_1$、$P_2$ 和 $P_3$，共有 12 台磁带机。进程 $P_1$ 共需要 10 台磁带机，$P_2$ 和 $P_3$ 分别需要 4 台和 9 台。假设在 $T_0$ 时刻，进程 $P_1$、$P_2$ 和 $P_3$ 已分别获得 5 台、2 台和 2 台，尚有 3 台未分配，见下表。

|进程|最大需求|已分配|可用|
|:---:|:---:|:---:|:---:|
|$P_1$|10|5|3|
|$P_2$|4|2||
|$P_3$|9|2||

在 $T_0$ 时刻是安全的，因为存在一个安全序列 $P_2$、$P_1$、$P_3$，即只要系统按此进程序列分配资源，那么每个进程都能顺利完成。若在 $T_0$ 时刻后，系统分配 1 台磁带机给 $P_3$，则此时系统便进入不安全状态，因为此时已无法再找到一个安全序列。

并非所有的不安全状态都是死锁状态，但当系统进入不安全状态后，便可能进入死锁状态；反之，只要系统处于安全状态，系统便可避免进入死锁状态。

### 银行家算法

银行家算法是最著名的死锁避免算法，其思想是：把操作系统视为银行家，操作系统管理的资源相当于银行家管理的资源，进程向操作系统请求分配资源相当于用户向银行家贷款。操作系统按照银行家指定的规则为进程分配资源，当进程首次申请资源时，要测试该进程对资源的最大需求量，若系统现存的资源可以满足它的最大需求量，则按当前的申请量分配资源，否则就推迟分配。当进程的执行中继续申请资源时，先测试该进程已占用的资源数与本次申请的资源数之和是否超过该进程对资源的最大需求量。若超过则拒绝分配资源，若未超过则再测试系统现存的资源能否满足该进程尚需的最大资源量，若能满足则按当前的申请量分配资源，否则也要推迟分配。

#### （1）数据结构描述

可利用资源向量 Available：含有 m 个元素的数组，其中每个元素代表一类可用的资源数目。Available[j]=K 表示系统中现有 $R_j$ 类资源 K 个。

最大需求矩阵 Max：nxm 矩阵，定义系统中 n 个进程中的每个进程对 m 类资源的最大需求。简单来说，一行代码一个进程，一列代表一类资源。Max[i,j]=K 表示进程 i 需求 $R_j$ 类资源的最大数目为 K。

分配矩阵 Allocation：nxm 矩阵，定义系统中每类资源当前已分配给每个进程资源数。Allocation[i,j]=K 表示进程 i 当前已分得 $R_j$ 类资源的数目为 K。初学者容易混淆 Available 向量和 Allocation 矩阵，在此特别提醒。

需求矩阵 Need：nxm矩阵，表示每个进程尚需的各类资源数。Need[i,j]=K 表示进程 i 还需要 $R_j$ 类资源的数目为 K。

上述三个矩阵间存在下述关系：

$$
Need = Max-Allocation
$$

一般情况下，在银行家算法的题目中，Max 矩阵和 Allocation 矩阵是已知条件，而求出 Need 矩阵的解题的第一步。

#### （2）银行家算法描述

设 $Request_i$ 是进程 $P_i$ 的请求向量，$Request_i[j]=K$ 表示进程 $P_i$ 需求 j 类资源 K 个。当 $P_i$ 发出资源请求后，系统按下述步骤进行检查：

1. 若 $Request_i[j] \leq Need[i,j]$，则转向步骤 2；否则认为出错，因为它需要的资源数已超过它所宣布的最大值。
2. 若 $Request_i[j] \leq Available[j]$，则转向步骤 3；否则，表示尚无足够资源，$P_i$ 须等待。
3. 系统试探着把资源分配给进程 $P_i$，并修改下面数据结构中的数值：
   
   $$
   	Available = Available-Request_i; \\
   	Allocation[i,j]=Allocation[i,j]+Request_i[j]; \\
   	Need[i,j]=Need[i,j]-Request_i[j]; \\
   $$
   
4. 系统执行安全性算法，检查此次资源分配后，系统是否处于安全状态。若安全，才正式将资源分配给进程 $P_i$，以完成本次分配；否则，将本次的试探分配作废，恢复原来的资源分配状态，让进程 $P_i$ 等待。

#### （3）安全性算法

1. 初始时安全序列为空。
2. 从 Need 矩阵中找出符合下面条件的行：该行对应的进程不在安全序列中，而且该行小于等于 Available 向量，找到后，把对应的进程加入安全序列；若找不到，则执行步骤 4。
3. 进程 $P_i$ 进入安全序列后，可顺利执行，直至完成，并释放分配给它的资源，故应执行 Available = Available + Allocation[i]。其中 Allocation[i] 表示进程 $P_i$ 代表的在 Allocation 矩阵中对应的行。返回步骤 2。
4. 若此时安全序列中已有所有进程，则系统处于安全状态，否则系统处于不安全状态。

读者首次看完上面对银行家算法的过程描述后，可能会有眼花缭乱的杆菌，现在用一个例子来加深理解。

### 安全性算法举例 需修改

假定系统中有 5 个进程 {$P_0,P_1,P_2,P_3,P_4$} 和三类资源 {A,B,C}，各种资源的数量分别为10、5、7，在 $T_0$ 时刻的资源分配情况下表。

|进程资源情况|Max <br/> A B C|Allocation <br/> A B C|Available <br/> A B C|
|:---:|:---:|:---:|:---:|
|$P_0$|7 5 3|0 1 0||
|$P_1$|3 2 2|2 0 0 <br/> (3 0 2)|3 3 2 <br/> (2 3 0)|
|$P_2$|9 0 2|3 0 2||
|$P_3$|2 2 2|2 1 1||
|$P_4$|4 3 3|0 0 2||

$T_0$ 时刻的安全性。利用安全性算法对 $T_0$ 时刻的资源分配进行分析。

1. 从题目中我们可以提取 Max 矩阵和 Allocation 矩阵，这两个矩阵相减可得到 Need 矩阵

省略了

## 死锁检测和解除

前面介绍的死锁预防和避免算法，都是在为进程分配资源时施加限制条件或进行检测，若系统为进程分配资源时不采取任何措施，则应该提供死锁检测和解除的手段。

### 资源分配图

系统死锁可利用资源分配图来描述。如下图所示，用圆圈代表一个进程，用框代表一类资源。由于一种类型的资源可能有多个，因此用框中的一个圆代表一类资源中的资源。从进程到资源的有向边称为请求边，表示该进程申请一个单位的该类资源；从资源到进程的边称为分配边，表示该类资源已有一个资源分配给了该进程。

images（王道 图 2.13 资源分配示例）

在上图所示的资源分配图中，进程 $P_1$ 已经分得了两个 $R_1$ 资源，并又请求一个 $R_2$ 资源；进程 $P_2$ 分得了 $R_1$ 资源和一个 $R_2$ 资源，并又请求一个 $R_1$ 资源。

### 死锁定理

简化资源分配图可检测系统状态 S 是否为死锁状态。简化方法如下：

1. 在资源分配图中，找出既不阻塞又不孤点的进程 $P_i$（既找出一条有向边与它相连，且该有向边对应资源的申请数量小于等于系统中已有的空闲资源数量，如在上图中，$R_1$ 没有空闲资源，$R_2$ 有一个空闲资源。若所有连接该进程的边均满足上述条件，则这个进程能继续运行直至完成，然后释放它所占有的所有资源）。消去它所有的请求边和分配边，使之成为孤立的结点。在下图(a)中，$P_1$ 是满足这一条件的进程结点，将 $P_1$ 的所有边消去，便得到下图(b)所示的情况。
   这里要注意一个问题，判断某种资源是否有空闲，应用它的资源数量减去它在资源分配图中的出度，例如在上图中，$R_1$ 的资源数为 3，而出度也为 3，所以 $R_1$ 没有空闲资源，$R_2$ 的资源数为 2，出度为 1，所以 $R_2$ 有一个空闲资源。

2. 进程 $P_i$ 所释放的资源，可以唤醒某些因等待这些资源而阻塞的进程，原来的阻塞进程可能变为非阻塞进程。在上图中，进程 $P_2$ 就满足这样的条件，根据 1 中的方法进行一系列简化后，若能消去图中所有的边，则称该图是可完全简化的，如下图(c) 所示。

images（王道 图 2.14 资源分配图的简化）

S 为死锁的条件是当且仅当 S 状态的资源分配图是不可完全简化的，该条件为死锁定理。

### 死锁解除

一旦检测出死锁，就应立即采取相应的措施来解除死锁。死锁解除的主要方法有：

1. 资源剥夺法。挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但应防止被挂起的进程长时间得不到资源而处于资源匮乏的状态。
2. 撤销进程法。强制撤销部分甚至全部死锁进程并剥夺这些进程的资源。撤销的原则可以按进程优先级和撤销进程代价的高低进行。
3. 进程回退法。让一（或多）个进程回退到足以回避死锁的地步，进程回退时自愿释放资源而非被剥夺。要求系统保持进程的历史信息，设置还原点。